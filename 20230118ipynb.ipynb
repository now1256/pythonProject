{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiLwaN3qtltmM2l6ZXoTrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/now1256/pythonProject/blob/master/20230118ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLqxkrIGuvnG",
        "outputId": "363b3edb-23dd-4c83-cd2b-f7814a538813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Installing collected packages: torch, install, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed install-1.3.5 torch-1.8.0 torchtext-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from Konlpy) (4.9.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from Konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->Konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->Konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, Konlpy\n",
            "Successfully installed JPype1-1.4.1 Konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        " !pip install install torch==1.8.0 torchtext==0.9.0\n",
        " !pip install Konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pickle \n"
      ],
      "metadata": {
        "id": "ewdUbZulu1m_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lEZdtdmu6X2",
        "outputId": "88247741-b6bc-4b40-9b90-3ccafca18193"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# txt파일을 다운 받음 \n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "# pandas를 이용하여 data를 따로 저장해놓음\n",
        "train_data=pd.read_table('ratings_train.txt')\n",
        "test_data=pd.read_table('ratings_test.txt')"
      ],
      "metadata": {
        "id": "vf9VR04EvSax"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#피클화 데이터 토큰이 너무 오래걸려서\n",
        "def load_pickle(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def save_pickle(data, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(data, f)"
      ],
      "metadata": {
        "id": "qzNfuC4_t3wP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련용 리뷰 개수 출력\n",
        "print('훈련용 리뷰 개수 :',len(train_data))\n",
        "\n",
        "# 테스트용 리뷰 개수\n",
        "print('테스트용 리뷰 개수 :',len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohr874duvv6G",
        "outputId": "8b246883-9441-4b5c-af44-04ebd15cb85f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 리뷰 개수 : 150000\n",
            "테스트용 리뷰 개수 : 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4000개 정도 중복 됨 label은 0,1값 2개만 존재 \n",
        "print(train_data['document'].nunique(), train_data['label'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SiaphDBwQt9",
        "outputId": "6e1fae50-cd57-40e6-e0fc-34edd10b999e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146182 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doucument 열의 중복 제거\n",
        "train_data.drop_duplicates(subset=['document'], inplace=True)"
      ],
      "metadata": {
        "id": "x6T5G_rUwYLj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플 확인\n",
        "print('총 샘플의 수 :',len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1xkzrwFwqB9",
        "outputId": "ca7bbabe-424e-4f56-b484-3a25aa114a94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 수 : 146183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확 한 값의 개수\n",
        "print(train_data.groupby('label').size().reset_index(name = 'count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3j3suidwqqT",
        "outputId": "3b0fb557-9620-4f44-ea3f-b65850e3f503"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label  count\n",
            "0      0  73342\n",
            "1      1  72841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# null 값 확인\n",
        "print(\"null값의 존재 여부 :\", train_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT2oP4hiw6FM",
        "outputId": "8748bbec-2d72-402e-a698-4a3c6e46c188"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "null값의 존재 여부 : id          0\n",
            "document    1\n",
            "label       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Null 값이 존재하는 행 제거\n",
        "train_data = train_data.dropna(how = 'any')"
      ],
      "metadata": {
        "id": "bM0a_fTTxDDY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Null 값이 존재하는 지 확인\n",
        "print(\"Null 값 존재: \",train_data.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vACV8b3-xw8Z",
        "outputId": "68d208eb-3440-453d-9d7d-4d7c493966af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null 값 존재:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Null 값을 가진 샘플 제거 됬는지 확인 -> 1개가 줄었으면 맞음 \n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFe9sCSkxy00",
        "outputId": "20393bea-2f56-4d30-ad25-070ed8e996d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "# 한글과 공백을 제외하고 모두 제거\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBl9-LUGx1lH",
        "outputId": "d9d60cb1-5b68-449f-e01a-3b42cc5740cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-28e68038176e>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#공백인 empty칸을 null로 바꿔줌\n",
        "train_data['document'] = train_data['document'].str.replace('^ +', \"\")\n",
        "train_data['document'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKAzS-fWx9Oi",
        "outputId": "864352ee-0f68-4ab9-a059-8ee95e0ebcdc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id            0\n",
            "document    789\n",
            "label         0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-dca8c273f009>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  train_data['document'] = train_data['document'].str.replace('^ +', \"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#특수기호를 제외하니 생긴 Null 값을 제거\n",
        "train_data = train_data.dropna(how = 'any')\n",
        "print(\"특수 기호를 제외한 나머지 데이터 값\",len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_v58VjoyH1z",
        "outputId": "c37816fc-2692-4404-e18f-af13793fcd99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특수 기호를 제외한 나머지 데이터 값 145393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 셋도 위와 같이 전처리\n",
        "#중복제거\n",
        "test_data.drop_duplicates(subset = ['document'], inplace=True)\n",
        "#한글과 공백뺴고 제거\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# empty space- > null\n",
        "test_data['document'] = test_data['document'].str.replace('^ +', \"\")\n",
        "test_data['document'].replace('', np.nan, inplace=True)\n",
        "# null값 제거\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f80BgCxFyWh6",
        "outputId": "a7faec61-02d4-4388-b817-efe41edf091f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후 테스트용 샘플의 개수 : 48852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-ae8dd1d24807>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
            "<ipython-input-18-ae8dd1d24807>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test_data['document'] = test_data['document'].str.replace('^ +', \"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 stopwords -> 형태소 분리할때 효율적으로 할 수 있게 제거 \n",
        "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']"
      ],
      "metadata": {
        "id": "FIBFN1-UyZp-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 형태소 분석기 KoNLPy의 Okt를 사용\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "8wIgSbD3yypF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "for sentence in tqdm(train_data['document']):\n",
        "    #stem=True의 경우 어느정도 정규화를 해줌\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
        "    # for문 한줄로 이거 공부해야함\n",
        "    # 불용어 제거를 함\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]\n",
        "    X_train.append(stopwords_removed_sentence)\n",
        "print(X_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTiEBPHUzJtW",
        "outputId": "36be945f-9607-453d-864d-954224c2387f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 145393/145393 [09:53<00:00, 244.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['아', '더빙', '진짜', '짜증나다', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'], ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testset 또한 같이 토큰화 해놓음\n",
        "X_test = []\n",
        "for sentence in tqdm(test_data['document']):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if word not in stopwords]\n",
        "    X_test.append(stopwords_removed_sentence)\n",
        "print(X_test[:3])    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHb0rVjEzq7j",
        "outputId": "1827ca74-941a-4e00-8271-d51d7f2ed79d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48852/48852 [03:28<00:00, 234.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['굳다', 'ㅋ'], ['뭐', '야', '평점', '나쁘다', '않다', '점', '짜다', '리', '더', '더욱', '아니다'], ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기', '에는']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnmyfBnMuERV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩\n",
        "# 빈도수 계산 도구 FreqDist()\n",
        "vocab = FreqDist(np.hstack(X_train))\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iAVGkhi0F3N",
        "outputId": "053d1693-226b-4f4b-fd6e-2623774d3597"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 43752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 19416\n",
        "# 상위 vocab_size개의 단어만 보존 vocab size 줄임 \n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNRq0mQQ6JCN",
        "outputId": "953bf10d-4705-467c-e8d7-810c5f342a1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 19416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴한\n",
        "# 0은 패딩 1은 모르는 값\n",
        "word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}\n",
        "word_to_index['pad'] = 0\n",
        "word_to_index['unk'] = 1"
      ],
      "metadata": {
        "id": "A7yNyMCp_3zB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train 단어집합\n",
        "encoded = []\n",
        "for line in X_train: #입력 데이터에서 1줄씩 문장을 읽음\n",
        "    temp = []\n",
        "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
        "      try:\n",
        "        temp.append(word_to_index[w]) # 글자를 해당되는 정수로 변환\n",
        "      except KeyError: # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n",
        "        temp.append(word_to_index['unk']) # unk의 인덱스로 변환\n",
        "\n",
        "    encoded.append(temp)\n",
        "X_train = encoded    \n",
        "print(X_train[:10])\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQa9bwStFvY8",
        "outputId": "0d297b17-8c65-4b73-cbbe-2ebf5e8d1026"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[51, 455, 17, 261, 660], [934, 458, 42, 603, 2, 215, 1450, 25, 962, 676, 20], [387, 2445, 1, 2316, 5672, 3, 223, 10], [6493, 106, 8119, 219, 57, 5, 27, 3604], [1024, 19417, 30, 9146, 25, 834, 2, 2580, 22, 1109, 241, 14244, 1, 1077, 255, 241], [723, 5673, 981, 1388, 428, 144, 1693, 1627, 11561, 226, 2, 93, 127, 1082, 46, 246], [214, 315, 4, 325, 483], [127, 1082, 46, 333, 24, 9787, 14245, 299, 124, 1586, 369, 120, 227, 11, 798, 18, 580, 575, 519, 476, 3118, 8120, 15, 1389, 1389, 38, 286, 5, 25, 36, 41, 15, 704, 1073, 70], [95, 5, 57, 7, 369, 98, 2], [1536, 27, 202, 536, 83, 15, 393, 1440, 362, 667, 9, 5674, 7]]\n",
            "19416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test 단어집합 \n",
        "vocab = FreqDist(np.hstack(X_test))\n",
        "vocab_size = 19416\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}\n",
        "word_to_index['pad'] = 0\n",
        "word_to_index['unk'] = 1\n",
        "encoded = []\n",
        "for line in X_test: #입력 데이터에서 1줄씩 문장을 읽음\n",
        "    temp = []\n",
        "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
        "      try:\n",
        "        temp.append(word_to_index[w]) # 글자를 해당되는 정수로 변환\n",
        "      except KeyError: # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n",
        "        temp.append(word_to_index['unk']) # unk의 인덱스로 변환\n",
        "\n",
        "    encoded.append(temp)\n",
        "X_test = encoded    \n",
        "\n",
        "print(X_test[:10])\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRv6kelMGRcp",
        "outputId": "4c09d396-a2f9-44b0-cb54-15057bdf0087"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[614, 92], [65, 168, 24, 395, 20, 21, 280, 776, 45, 861, 18], [67, 20, 90, 380, 110, 112, 61, 151, 246], [14, 18, 127, 1784, 111, 61, 37, 19, 25, 176, 14706, 797], [226, 3159, 12, 29, 226, 2], [748, 72], [1090, 401, 302, 22, 2807, 10898, 5, 1785, 2808, 2180, 3624, 2605], [457, 1200, 12, 2128, 228, 54, 5, 2809, 694, 183, 48, 99, 2319, 228, 14707, 52, 396, 10899, 17, 2, 85, 421, 52, 2379, 6], [2702, 1639, 452, 3042, 579, 2703, 5458, 224, 40, 74, 20], [135, 339, 14, 7584, 14708, 390, 62]]\n",
            "19416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label값 받기 \n",
        "y_train = np.array(train_data['label'])\n",
        "y_test = np.array(test_data['label'])"
      ],
      "metadata": {
        "id": "vjyO21VDIcCf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
        "drop_train = [index for index, sentence in enumerate(X_test) if len(sentence) < 1]"
      ],
      "metadata": {
        "id": "SqZLZMP4Oesu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈 샘플들을 제거\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcbM9Gv_PDP_",
        "outputId": "cc447653-e44e-453d-ac45-58356979cef6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145391\n",
            "145391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = asarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.delete(X_test, drop_train, axis=0)\n",
        "y_test = np.delete(y_test, drop_train, axis=0)\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSAkIoccPDw3",
        "outputId": "60683376-e311-477d-98d4-2341db1fb0cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48850\n",
            "48850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(review) for review in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "S6D7hElHP59S",
        "outputId": "9510c148-a8df-47d5-fd24-57c759ea83fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 72\n",
            "리뷰의 평균 길이 : 11.001258674883589\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max len을 확인하는 함수 \n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "7-26p8fWP7Bb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 30\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8U0i9z0QS9Y",
        "outputId": "0f4e993f-08f9-4475-b083-aae13a2005cf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 30 이하인 샘플의 비율: 94.08354024664526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "print(\"X_train의 shape: \",X_train.shape)\n",
        "print(\"X_test의 shape: \",X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI0E7gOZQTgC",
        "outputId": "7fa067ee-7e18-4f9f-8bca-bffa92cd3e8a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train의 shape:  (145391, 30)\n",
            "X_test의 shape:  (48850, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train set과 val set x, y 분리 \n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, shuffle=False, random_state=1004)"
      ],
      "metadata": {
        "id": "2b8WfOZBgAWP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 변환\n",
        "X_train = torch.LongTensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "\n",
        "X_val = torch.LongTensor(X_val)\n",
        "y_val = torch.LongTensor(y_val)\n",
        "\n",
        "X_test = torch.LongTensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "print(X_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr-AMXdVg-Z-",
        "outputId": "283ce7d8-7da9-46d8-8b1f-faf235228bd3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([87234, 30]) torch.Size([87234])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토체의 데이터 셋에 넣음 \n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "var_data = TensorDataset(X_val, y_val)\n",
        "test_data = TensorDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "8arE-hIThHfS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터로더를 만듬 \n",
        "train_data_dataloader = DataLoader(dataset=train_data, batch_size=256, shuffle=True)\n",
        "val_data_dataloader = DataLoader(dataset=var_data,batch_size=256, shuffle=True)\n",
        "test_data_dataloader = DataLoader(dataset=test_data,batch_size=256, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Jz0T8LpdhVtA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 모델 구현 \n",
        "\n",
        "# 시드 고정\n",
        "SEED = 5\n",
        "random.seed(SEED)  \n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# 하이퍼파라미터\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "7ormZEtfemYB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU를 이용 \n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.embed(x)  # 이것때문에 에러가 났음 \n",
        "        h_0 = self._init_state(batch_size=x.size(0))  # 첫번째 히든 스테이트를 0벡터로 초기화\n",
        "        x, _ = self.gru(x, h_0)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
        "        h_t = x[:, -1, :]  # (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n"
      ],
      "metadata": {
        "id": "OhSh7BO7esTs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRU(1, 256, 19418, 128, 2, 0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "KktE0buxfERz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_data_dataloader):\n",
        "    model.train()\n",
        "    for batch_idx, samples in (enumerate(train_data_dataloader)):\n",
        "        x, y = samples\n",
        "        # y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "        optimizer.zero_grad()\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "G4Fq9ULIfR7e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_data_dataloader):\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch_idx, samples in enumerate(val_data_dataloader):\n",
        "        x, y = samples\n",
        "        # y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_data_dataloader.dataset) # 이거 뭘 가르키는지 모르겠음 \n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "vOJTw3QVfc5O"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = None\n",
        "print(\"학습 시작!!!!\")\n",
        "for e in range(1, EPOCHS):\n",
        "    train(model, optimizer, train_data_dataloader) \n",
        "    val_loss, val_accuracy = evaluate(model, val_data_dataloader)\n",
        "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss\n",
        "   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-VPqS7WfmqS",
        "outputId": "fc3075a4-7d86-441b-d601-674ddffb7f3b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 시작!!!!\n",
            "[Epoch: 1] val loss :  0.42 | val accuracy : 80.60\n",
            "[Epoch: 2] val loss :  0.38 | val accuracy : 82.96\n",
            "[Epoch: 3] val loss :  0.37 | val accuracy : 83.80\n",
            "[Epoch: 4] val loss :  0.39 | val accuracy : 83.91\n",
            "[Epoch: 5] val loss :  0.44 | val accuracy : 83.24\n",
            "[Epoch: 6] val loss :  0.54 | val accuracy : 83.07\n",
            "[Epoch: 7] val loss :  0.63 | val accuracy : 82.61\n",
            "[Epoch: 8] val loss :  0.79 | val accuracy : 83.04\n",
            "[Epoch: 9] val loss :  0.84 | val accuracy : 82.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_data_dataloader)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "konpqZIKDFiN",
        "outputId": "3f104ad7-94b8-4187-8cc5-4afce26a3d44"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 오차:  1.00 | 테스트 정확도: 55.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
        "  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  \n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  print(encoded)\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len ) # 패딩\n",
        "  pad_new = torch.LongTensor(pad_new)\n",
        "  print(pad_new.shape)\n",
        "  print(pad_new)\n",
        "  score = float(model(pad_new)) # 예측\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
      ],
      "metadata": {
        "id": "NodUOJgfGrvL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input('영화리뷰를 써주세요 : ')\n",
        "print(text)\n",
        "sentiment_predict(text)"
      ],
      "metadata": {
        "id": "5RtZ5WnvKY4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGFfZxcuSO7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}